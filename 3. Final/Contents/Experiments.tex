\chapter{Experiments}
\section{Dataset Preparation}
After the selection of our Dataset which is IStego100K\cite{7}, now we need to further process this dataset. It was not feasible to train the model using all data at once. So, Initially we splitted the dataset into different batches. Each batch consisting of 40,000 images (20000 cover images and 20000 stego images). We tried to train the model using this subset of datset but there was mermory Limitation problem. We then reduced the batch size to 30,000 (15,000 cover images and 15,000 stego images), but still faced the same issue. Finally, we set the batch size to 20,000 (10,000 cover and 10,000 stego), which allowed the training process to proceed successfully. To split the dataset, we utilized a Microsoft PowerShell script, which splitted the dataset into the desired subsets and stored them in respective subfolders.

\section{Trainig the Ensemble Model}
Before training the model, it was necessary to identify the most suitable features for our project. Therefore, we conducted several tests to determine the optimal feature set for training our model.
\subsection{DCTR Feature}
Initially, we used (DCTR) features with a feature dimensionality of 8000 for training our model. However, we faced several challenges: the feature extraction process was time-consuming, and the outcomes were unsatisfactory.\\
\begin{figure}[H]
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/rocdctr.jpg}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/saturationdctr.jpg}
    \end{subfigure}
    \caption{ROC curve and OOB vs No of base learner [DCTR]}
\end{figure}
\begin{figure}[H]
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/histoDctr.jpg}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/confusiondctr.jpg}
    \end{subfigure}
    \caption{Histogram and Confusion Matrix [DCTR]}
\end{figure}
Using DCTR as feacture vector for trainig the model we gotArea Under the Curve (AUC) of 0.59 which is quite low. We tried using different sub-set of data set but result was still same. Above graphs shows ROC curve, OOB error vs number of base learner, confusion matrix and histogram of votes.
\clearpage
\subsection{CC-CN Feature}
Later on, we came across cc-cN features, specifically cc-c300, which provided a higher dimensionality of 48600. These features proved to be more effective in capturing dependencies among individual cover elements. Due to the large dimensionality of our images, we used for Fisher's Linear Discriminant (FLD) as the base learner for our ensemble classifier. As a result, we observed improved performance compared to our earlier one.\\
\begin{figure}[H]
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/ROC300.jpg}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/saturation300.jpg}
    \end{subfigure}
    \caption{ROC and Search for subspace dimensionality [CC-C300]}
\end{figure}
\begin{figure}[H]
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/histo300.jpg}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/confusion300.jpg}
    \end{subfigure}
    \caption{Histogram and Confusion Matrix [CC-C300]}
\end{figure}
\clearpage
\subsection{CC-CHEN Feature}
We looked into another feature extraction method called cc-chen, which had 972 dimensions, to see if it was better than cc-c300. However, the results weren't as good as with cc-c300. So, we decided that cc-c300 was the best choice for our project.\\
\begin{figure}[H]
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/ROCchen.png}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/saturationchen.png}
    \end{subfigure}
    \caption{ROC and Search for subspace dimensionality [CC-CHEN]}
\end{figure}
\begin{figure}[H]
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/histochen.png}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/confusionChen.png}
    \end{subfigure}
    \caption{Histogram and Confusion Matrix [CC-CHEN]}
\end{figure}
\begin{flushleft}
Table below contiain summary of the performance of the model with different features.
\end{flushleft}
\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|l|l|l|}
    \hline
    Feature & Accuracy & Precision & Recall & F1 Score \\ \hline
    DCTR    & 0.56   & 0.55    & 0.56 & 0.56  \\ \hline
    CC-CHEN & 0.61     & 0.70      & 0.59   & 0.65     \\ \hline
    CC-C300 & 0.66     & 0.73      & 0.64   & 0.68     \\ \hline
    \end{tabular}
    \caption{Performance of the model with different features}
\end{table}
\clearpage
\section{Changing different parameters}
After comparing with two other features we decied to choose CC-C300 feature. To get the optimal result we trained our model with different value of dsub and number of base learner. The results are shown below:
\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|l|l|l|}
    \hline
    No of  Base Learner & Subspace size & Accuracy & Precision & Recall \\ \hline
    120                 & 800           & 0.6947   &    0.79       &  0.60      \\ \hline
    100                 & 1400         & 0.7045   &    0.64       &   0.62     \\ \hline
    160                 & 2600         & 0.7116   &    0.73       &    0.64    \\ \hline
    \end{tabular}
    \caption{Performance of the model with different parameters}
\end{table}

\begin{figure}[H]
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/800/rocgray.jpg}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/800/saturategray.jpg}
    \end{subfigure}
    \caption{ROC curve and OOB vs No of base learner[dsub=800]}
\end{figure}
\begin{figure}[H]
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/800/histogramgray.jpg}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/800/confusegray.jpg}
    \end{subfigure}
    \caption{Histogram and Confusion Matrix [dsub=800]}
\end{figure}
Using 800 sub space dimensionality with CC-C300 feature vector we got Area Under the Curve (AUC) of 0.6947. The ROC curve, OOB error vs number of base learner, confusion matrix and histogram of votes are shown in the above graphs. The OOB error was minimum when number of base learner was 120. In this process we made sub space dimensionality constant of 800 while number of base learner to automatically get selected when OOB error was minimum.

\begin{figure}[H]
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/1400/gray1400roc.jpg}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/1400/gray1400saturate.jpg}
    \end{subfigure}
    \caption{ROC curve and OOB vs No of base learner [dsub=1400]}
\end{figure}
\begin{figure}[H]
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/1400/gray1400histo.jpg}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/1400/gray1400confuse.jpg}
    \end{subfigure}
    \caption{Histogram and Confusion Matrix [dsub=1400]}
\end{figure}

\begin{figure}[H]
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/2600/roc2600.jpg}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/2600/staturAATE2600.jpg}
    \end{subfigure}
    \caption{ROC curve and OOB vs No of base learner[dsub=2600]}
\end{figure}
\begin{figure}[H]
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/2600/histo2600.jpg}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{img/2600/consuse2600.jpg}
    \end{subfigure}
    \caption{Histogram and Confusion Matrix [dsub=2600]}
\end{figure}
\clearpage

\section{Comparison between MATLAB and Python}
The decision between MATLAB and Python as our primary platform was influenced by the availability of feature extraction tools. Since our feature extraction process was exclusive to MATLAB, we were inclined to opt for MATLAB. Although the functionality to call and use python engine inside MATLAB is available but there are limitations to their usage as there are version compatibility issues. For the functionality of using python in MATLAB we require matlabengine which has various bugs and they have various version compatibility issues as well.\\
There are also various procedure which had to be carefully followed in order to properly execute python libraries. 
Thus, although itâ€™s possible to call MATLAB functions from Python, limitations such as version compatibility and slower execution using MATLAB Engine prompted us to stick with MATLAB for feature extraction\\
For the creation of the demos, there were functionalities to create app demo using MATLAB as backend and frontend as well but it required matlabengine which had as afore mentioned various compatibility issues. So, we opted to use MATLAB's matlab app designer functionality for creating a demo app without the need of matlabengine.






% In assessing classification methods, we experimented with using a Random Forest ensemble classifier in Python. The model's performance and accuracy closely matched those obtained using MATLAB.\\

% The decision between MATLAB and Python as our primary platform was influenced by the availability of feature extraction tools. Since our feature extraction process was exclusive to MATLAB, we opted for it. Although it's possible to call MATLAB functions from Python, limitations such as version compatibility and slower execution using MATLAB Engine prompted us to stick with MATLAB for feature extraction.\\
% TO call matlab from python it requires matlabengine. matlabengine is bla bla matlab ko version anusar python ko version vary garna parcha........ \\

% For creating a demo, we investigated using MATLAB as a backend. It was possible but again it rquired matlabengine. so we used matlab app designer for the UI. mmatlab app designer is bla bla bla
% k chutyo?
% about matlab Engine
% about matlab app designer
% why matlab engine not used---------> slower
% why matlab app designer used-----------> backend ma matlab engine use hune vayera 